{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d61bcfc-01ed-4b80-b768-b9243dfc8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from geopy.distance import geodesic as GD\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a08aad63-37e1-464a-8756-0736e57a2f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.jobbank.gc.ca/jobsearch/jobsearch?flg=E&fcan=1&fss=1&fss=C&fwcl=B&fwcl=C&fwcl=D&fwcl=E&fglo=1&sort=M&fwht=D&fwht=M&fsrc=16&fjnc=1&fexp=0&fexp=1&fprov=AB&fprov=ON&fskl=101020&fskl=101010'\n",
    "page=requests.get(url)\n",
    "\n",
    "soup=BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "job_elements=soup.find_all('a', class_='resultJobItem')\n",
    "id_search=soup.find_all('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4167c41-f255-466a-88c3-be653506ebdc",
   "metadata": {},
   "source": [
    "**Sending requests and retrieving information from job listing summaries**\n",
    "\n",
    "To scrape the main webpage for job listings, I accessed the job search URL to retrieve the page content, used an HTML parser to process the content, and extracted all job listing elements by identifying specific HTML tags and classes associated with the job postings, allowing me to gather summary information about various job listings from the main page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d615e918-8db2-4c0e-a4d8-7c3fd69cc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "role_list=[]\n",
    "dates_list=[]\n",
    "business_list=[]\n",
    "locations_list=[]\n",
    "salaries_list=[]\n",
    "id_list=[]\n",
    "noccode_list=[]\n",
    "employment_type_list=[]\n",
    "job_duration_list=[]\n",
    "education_list=[]\n",
    "experience_list=[]\n",
    "address_list=[]\n",
    "weekly_hours_list=[]\n",
    "vacancies_list=[]\n",
    "work_permit_list=[]\n",
    "\n",
    "jobs={\n",
    "    \n",
    "    'ID':id_list,\n",
    "    'ROLES':role_list,\n",
    "    'SALARY':salaries_list,\n",
    "    'EDUCATION':education_list,\n",
    "    'EXPERIENCE':experience_list,\n",
    "    'NOC CODE':noccode_list,\n",
    "    'BUSINESS':business_list,\n",
    "    'LOCATIONS':locations_list,\n",
    "    'PUBLISHED DATES':dates_list,\n",
    "    'EMPLOYMENT TYPE':employment_type_list,\n",
    "    'JOB DURATION':job_duration_list,\n",
    "    'WEEKLY HOURS':weekly_hours_list,\n",
    "    'VACANCIES':vacancies_list,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def role_finder(job_list):\n",
    "    role=job_list.find('span', class_='noctitle')\n",
    "    if role:\n",
    "        fixed_role=role.find(string=True, recursive=False).strip() #Cuando usas Recursive, no pone los datos de los dem√°s \"span\".\n",
    "        role_list.append(fixed_role)\n",
    "    else:\n",
    "        role_list.append('Null')\n",
    "\n",
    "def published_date_finder(job_list):\n",
    "    published_date=job_list.find('li', class_='date')\n",
    "    if published_date:\n",
    "        fixed_date=published_date.find(string=True, recursive=False).strip() \n",
    "        dates_list.append(fixed_date)\n",
    "    else:\n",
    "        dates_list.append('Null')\n",
    "\n",
    "def business_name_finder(job_list):\n",
    "    business_name=job_list.find(class_='business')\n",
    "    if business_name:\n",
    "        fixed_business=business_name.find(string=True, recursive=False).strip()\n",
    "        business_list.append(fixed_business)\n",
    "    else:\n",
    "        business_list.append('Null')\n",
    "\n",
    "def location_finder(job_list):\n",
    "    location=job_list.find('li', class_='location').get_text()\n",
    "    if location:\n",
    "        fixed_location=location[10:].strip()\n",
    "        locations_list.append(fixed_location)\n",
    "    else:\n",
    "        locations_list.append('Null')\n",
    "    \n",
    "def salary_finder(job_list):\n",
    "    salary=job_list.find(class_='salary').get_text()\n",
    "    if salary:\n",
    "        fixed_salary=salary[30:].strip()\n",
    "        if 'hourly' in fixed_salary:\n",
    "            fix_sal=fixed_salary[:5]\n",
    "        if 'anually' in fixed_salary:\n",
    "            fix_sal=(fixed_salary[:9].replace(\",\",\"\"))/2000\n",
    "        salaries_list.append(f\"$\"+fix_sal)\n",
    "    else:\n",
    "        salaries_list.append('Null')\n",
    "\n",
    "def id_number_finder(every_id):\n",
    "        id=every_id.get('href')\n",
    "        try:\n",
    "            id.split('/')[-1:]\n",
    "            id_number=id[22:30]\n",
    "            try:\n",
    "                id_number=int(id_number)\n",
    "                id_list.append(id_number)\n",
    "            except:\n",
    "                pass\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c767ff7e-69de-424a-8948-246b94462ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Published date: ['July 22, 2024', 'July 19, 2024', 'July 17, 2024', 'July 17, 2024', 'July 15, 2024', 'July 12, 2024', 'July 10, 2024', 'July 10, 2024', 'July 09, 2024', 'July 08, 2024', 'July 08, 2024', 'July 08, 2024', 'July 08, 2024', 'July 08, 2024', 'July 08, 2024', 'July 07, 2024', 'July 05, 2024', 'July 04, 2024', 'July 04, 2024', 'July 04, 2024', 'July 04, 2024', 'July 04, 2024', 'July 04, 2024', 'July 03, 2024', 'July 03, 2024'] \n",
      "\n",
      "Role: ['assembler, plastic products', 'driller - oil and gas drilling', 'insurance agent', 'medical administrative assistant', 'guard, security', 'farm worker, general', 'food service supervisor', 'cook', 'maintenance person - building', 'kitchen helper', 'supervisor, food services', 'cleaner', \"cook's helper\", 'shift manager - fast food restaurant', 'farm supervisor', 'truck dispatcher', 'delivery drivers supervisor', 'fruit farm labourer', 'long haul truck driver', 'long haul truck driver', 'cook', 'car mechanic', 'landscape worker', 'nursery worker', 'long haul truck driver'] \n",
      "\n",
      "Business: ['KP Building Products', 'Green Energy Services Inc', 'Jeff Cooke Insurance Agency Ltd', 'CHAULA MEHTA MEDICINE PROFESSIONAL CORPORATION', 'Central Protection Services Inc.', 'Ferme Philos inc.', 'MB Scarborough Inc.', '1000673112 ONTARIO CORP.', 'Holiday Inn Express Newmarket', 'D SPOT DESSERT CAFE', 'Bite Me Guelph Inc', '1537003 ALBERTA LTD.', 'Royal Spice', 'FMI National Inc', 'Scotlynn Sweetpac Growers Inc.', 'Alliance Transport Ltd.', 'BANSAL LOGISTICS INC.', \"THOMPSON'S ORCHARDS LTD\", 'Epic Trails Ltd.', 'Star Alberta Transport Corporation', '2689174 Ontario Inc.', 'Beeton Trucks and Minivan Store', 'Atlas Landscaping Inc', \"Sloan's Nursery & Christmas Trees\", 'Majha Wala Transportation Inc.'] \n",
      "\n",
      "Location: ['Alexandria (ON)', 'Sexsmith (AB)', 'Calgary (AB)', 'Mississauga (ON)', 'Edmonton (AB)', 'Sarsfield (ON)', 'Scarborough (ON)', 'Gloucester (ON)', 'Newmarket (ON)', 'Calgary (AB)', 'Guelph (ON)', 'Calgary (AB)', 'Windsor (ON)', 'Brampton (ON)', 'Vittoria (ON)', 'London (ON)', 'Various locations', 'Blenheim (ON)', 'Lethbridge (AB)', 'Calgary (AB)', 'Trenton (ON)', 'Beeton (ON)', 'Edmonton (AB)', 'Bothwell (ON)', 'Edmonton (AB)'] \n",
      "\n",
      "Salary: ['$22.82', '$26.00', '$32.21', '$25.00', '$19.00', '$16.71', '$17.00', '$16.55', '$21.00', '$15.50', '$18.00', '$20.00', '$16.70', '$17.30', '$21.63', '$28.85', '$28.00', '$16.55', '$31.50', '$27.80', '$18.50', '$28.00', '$19.25', '$16.71', '$29.50'] \n",
      "\n",
      "ID: [41498952, 41486235, 41475229, 41472895, 41460166, 41447597, 41433573, 41432480, 41426072, 41423047, 41422125, 41421898, 41421273, 41420737, 41420469, 41417176, 41412591, 41404305, 41403705, 41403673, 41403240, 41402614, 41400104, 41397063, 41396317, 86297406]\n"
     ]
    }
   ],
   "source": [
    "for job_list in job_elements:\n",
    "    role_finder(job_list)\n",
    "    published_date_finder(job_list)\n",
    "    business_name_finder(job_list)\n",
    "    location_finder(job_list)\n",
    "    salary_finder(job_list)\n",
    "\n",
    "for every_id in id_search:\n",
    "    id_number_finder(every_id)\n",
    "\n",
    "print('Published date:', dates_list, '\\n')\n",
    "print('Role:', role_list, '\\n')\n",
    "print('Business:', business_list, '\\n')\n",
    "print('Location:', locations_list, '\\n')\n",
    "print('Salary:', salaries_list, '\\n')\n",
    "print('ID:', id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57167f15-8880-4a45-ab0c-a78fc4d0affe",
   "metadata": {},
   "source": [
    "**Extract further information**. \n",
    "\n",
    "To gather detailed information for each job listing, such as weekly hours, we need to access the specific page associated with each job ID.\n",
    "\n",
    "While the main page provides a summary of job information, additional details are located on individual job pages. Each job can be accessed via a unique URL in the format: /jobsearch/jobposting/ID_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e348d970-f36d-437e-b515-849fdb2f4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def education_finder():\n",
    "    education=re.search(r'Education: ([^.]+)', description)\n",
    "    if education:\n",
    "        fixed_education=education.group(1)\n",
    "        education_list.append(fixed_education)\n",
    "    else:\n",
    "        education_list.append('Null')\n",
    "\n",
    "def experience_finder():\n",
    "    experience=re.search(r'Experience: ([^.]+)', description)\n",
    "    if experience:\n",
    "        fixed_experience=experience.group(1)\n",
    "        experience_list.append(fixed_experience)\n",
    "    else:\n",
    "        experience_list.append('Null')\n",
    "        \n",
    "def noccode_finder():\n",
    "    noccode=job_details.find('span', class_='aa_jobbank_job_noccode').get_text()\n",
    "    if noccode:\n",
    "        noccode_list.append(noccode)\n",
    "    else:\n",
    "        noccode_list.append('Null')\n",
    "    \n",
    "def employment_finder():\n",
    "    employment_type=job_details.find('span', property='employmentType')\n",
    "    if employment_type:\n",
    "    #SHIFT TYPE\n",
    "        fixed_employment_type=employment_type.find(string=True, Recursive=False).get_text()\n",
    "        employment_type_list.append(fixed_employment_type)\n",
    "\n",
    "    #JOB DURATION\n",
    "        for duration in employment_type:\n",
    "            job_duration=duration.get_text(strip=True)\n",
    "            job_duration_list.append(job_duration)\n",
    "            break\n",
    "    else:\n",
    "        employment_type_list.append('Null')\n",
    "        job_duration_list.append('Null')\n",
    "    \n",
    "def weekly_hours_finder():\n",
    "    weekly_hours=job_details.find('span', property='workHours')\n",
    "    if weekly_hours:\n",
    "        fixed_weekly_hours=weekly_hours.get_text(strip=True)\n",
    "        weekly_hours_list.append(fixed_weekly_hours)\n",
    "    else:\n",
    "        weekly_hours_list.append('Null')\n",
    "\n",
    "def address_finder():\n",
    "    address=job_details.find('span', property='addressLocality').get_text()\n",
    "    if address:\n",
    "        address_list.append(address)\n",
    "    else:\n",
    "        address_list.append('Null')\n",
    "        \n",
    "def vacancies_finder():\n",
    "    vacancies=job_details.find('span', string=re.compile(r'\\d+ vacancies')) #Various vacancies\n",
    "    if vacancies:\n",
    "        vacancy_number=re.search(r'\\d+', vacancies.get_text(strip=True)).group()\n",
    "        vacancies_list.append(vacancy_number)\n",
    "    else:\n",
    "        vacancies_list.append('1')\n",
    "\n",
    "def work_permit_finder():\n",
    "    work_permit=job_details.find(class_='job-posting-detail-apply').get_text()\n",
    "    if \"with or without a valid Canadian work permit\" in work_permit:\n",
    "        work_permit_list.append('No')\n",
    "    else:\n",
    "        work_permit_list.append('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe151aa-fa58-42a4-9ae4-3ec49238fd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 'NoneType' object has no attribute 'find'\n",
      "NOC Code: ['94212', '83101', '63100', '13112', '64410', '85100', '62020', '63200', '73201', '65201', '62020', '65310', '65201', '62020', '82030', '14404', '72024', '85101', '73300', '73300', '63200', '72410', '85121', '85103', '73300'] \n",
      "\n",
      "Employment Type: ['Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time', 'Full time'] \n",
      "\n",
      "Job Duration: ['Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Term or contract (ending: 2027-01-31)', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Permanent employment', 'Seasonal employment', 'Permanent employment'] \n",
      "\n",
      "Weekly Hours: ['84 hours bi-weekly', '40 to 60 hours per week', '35 to 40 hours per week', '30 to 44 hours per week', '30 hours per week', '50 hours per week', '35 hours per week', '30 to 40 hours per week', '30 hours per week', '30 to 40 hours per week', '35 to 40 hours per week', '30 hours per week', '35 hours per week', '35 hours per week', '30 to 40 hours per week', '35 hours per week', '35 hours per week', '30 to 55 hours per week', '40 to 60 hours per week', '50 to 60 hours per week', '35 to 44 hours per week', '35 hours per week', '40 hours per week', '40 to 60 hours per week', '30 to 50 hours per week'] \n",
      "\n",
      "Address: ['Alexandria', 'Sexsmith', 'Calgary', 'Mississauga', 'Edmonton', 'Sarsfield', 'Scarborough', 'Gloucester', 'Newmarket', 'Calgary', 'Guelph', 'Calgary', 'Windsor', 'Brampton', 'Vittoria', 'London', 'Kitchener', 'Blenheim', 'Lethbridge', 'Calgary', 'Trenton', 'Beeton', 'Edmonton', 'Bothwell', 'Edmonton'] \n",
      "\n",
      "Vacancies: ['3', '2', '2', '1', '5', '3', '1', '2', '1', '3', '3', '2', '1', '1', '5', '1', '3', '2', '4', '8', '2', '2', '5', '6', '2'] \n",
      "\n",
      "Education: ['No degree, certificate or diploma', 'Other trades certificate or diploma', 'Secondary (high) school graduation certificate', 'Secondary (high) school graduation certificate', 'Secondary (high) school graduation certificate', 'No degree, certificate or diploma', 'Secondary (high) school graduation certificate', 'Secondary (high) school graduation certificate', 'Secondary (high) school graduation certificate', 'No degree, certificate or diploma', 'Secondary (high) school graduation certificate', 'No degree, certificate or diploma', 'No degree, certificate or diploma', 'Secondary (high) school graduation certificate', 'No degree, certificate or diploma', 'Secondary (high) school graduation certificate', 'Secondary (high) school graduation certificate', 'No degree, certificate or diploma', 'No degree, certificate or diploma', 'Secondary (high) school graduation certificate', 'Secondary (high) school graduation certificate', 'Secondary (high) school graduation certificate', 'No degree, certificate or diploma', 'No degree, certificate or diploma', 'Secondary (high) school graduation certificate'] \n",
      "\n",
      "Experience: ['1 to less than 7 months', '1 to less than 7 months', '7 months to less than 1 year', 'Experience an asset', 'Will train', 'Experience an asset', '7 months to less than 1 year', 'Experience an asset', 'Experience an asset', 'Experience an asset', '7 months to less than 1 year', '1 to less than 7 months', 'Will train', '7 months to less than 1 year', '7 months to less than 1 year', '1 to less than 7 months', '7 months to less than 1 year', 'Will train', 'Experience an asset', '1 to less than 7 months', '1 to less than 7 months', 'Will train', 'Will train', 'Experience an asset', '1 to less than 7 months'] \n",
      "\n",
      "Work permit: ['Yes', 'Yes', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No', 'No', 'Yes', 'No', 'No', 'Yes', 'No'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ids in id_list:\n",
    "    try:\n",
    "        id_url='https://www.jobbank.gc.ca/jobsearch/jobposting/'+str(ids)\n",
    "        id_page=requests.get(id_url)\n",
    "        id_soup=BeautifulSoup(id_page.content, 'html.parser')\n",
    "        job_details=id_soup.find('main', class_='container')\n",
    "    \n",
    "        description = job_details.find('span', property='description').get_text()\n",
    "\n",
    "        education_finder()\n",
    "        experience_finder()\n",
    "        noccode_finder()\n",
    "        employment_finder()\n",
    "        weekly_hours_finder()\n",
    "        address_finder()\n",
    "        vacancies_finder()\n",
    "        work_permit_finder()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "        \n",
    "\n",
    "print('NOC Code:', noccode_list, '\\n')\n",
    "print('Employment Type:', employment_type_list, '\\n')\n",
    "print('Job Duration:', job_duration_list, '\\n')\n",
    "print('Weekly Hours:', weekly_hours_list, '\\n')\n",
    "print('Address:', address_list, '\\n')\n",
    "print('Vacancies:', vacancies_list, '\\n')\n",
    "print('Education:', education_list, '\\n')\n",
    "print('Experience:', experience_list, '\\n')\n",
    "print('Work permit:', work_permit_list, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f454b98-c00c-47a2-9a52-23275ce706d3",
   "metadata": {},
   "source": [
    "**Find nearest major city**\n",
    "\n",
    "For each job location, I removed any province-specific suffixes to standardize the city name. I then used a geolocation service to get the latitude and longitude of the job's city. I calculated the distance from this location to several predefined major cities (Edmonton, Red Deer, Calgary, Toronto, Ottawa) using geographic coordinates, improving the code's efficiency. The nearest major city and its distance were determined by finding the minimum distance among these calculated values, which were then added to the respective lists for further use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74416f83-d5b6-43b5-a136-74f895fb014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_city_list=[]\n",
    "distance_nearest_city_list=[]\n",
    "\n",
    "def calc_distance(fixed_location):\n",
    "    try:\n",
    "        city=re.sub(r'\\s*\\(AB\\)', '', fixed_location)\n",
    "    except:\n",
    "        city=re.sub(r'\\s*\\(ON\\)', '', fixed_location)\n",
    "\n",
    "    edmonton_coords=(53.5462055, -113.491241)\n",
    "    red_deer_coords=(52.2690628, -113.8141464)\n",
    "    calgary_coords=(51.0456064, -114.057541)\n",
    "    toronto_coords=(43.6534817, -79.3839347)\n",
    "    ottawa_coords=(45.4208777, -75.6901106)\n",
    "    \n",
    "    geolocator = Nominatim(user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0')\n",
    "    #big_cities=['Edmonton','Calgary','Red Deer','Toronto','Ottawa']\n",
    "    \n",
    "    location_city=geolocator.geocode(city)\n",
    "    city_coords=(location_city.latitude, location_city.longitude)\n",
    "\n",
    "    distance_journal={}\n",
    "\n",
    "    distance=round((GD(city_coords, edmonton_coords).km),2)\n",
    "    distance_journal['Edmonton']=distance\n",
    "    \n",
    "    distance=round((GD(city_coords, red_deer_coords).km),2)\n",
    "    distance_journal['Red_deer']=distance\n",
    "    \n",
    "    distance=round((GD(city_coords, calgary_coords).km),2)\n",
    "    distance_journal['Calgary']=distance\n",
    "\n",
    "    distance=round((GD(city_coords, ottawa_coords).km),2)\n",
    "    distance_journal['Ottawa']=distance\n",
    "\n",
    "    distance=round((GD(city_coords, toronto_coords).km),2)\n",
    "    distance_journal['Toronto']=distance\n",
    "\n",
    "    distance_nearest_city=min(distance_journal.values())\n",
    "    nearest_city= [key for key, value in distance_journal.items() if value==distance_nearest_city] \n",
    "    #print(f'Nearest big city: ',nearest_city,'-',distance_nearest_city,' kms')\n",
    "\n",
    "    nearest_city_list.append(nearest_city)\n",
    "    distance_nearest_city_list.append(distance_nearest_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1e8892-8951-49f5-80c0-4abfbde3b7f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEAREST CITY: [['Ottawa'], ['Edmonton'], ['Calgary'], ['Toronto'], ['Edmonton'], ['Ottawa'], ['Toronto'], ['Ottawa'], ['Toronto'], ['Calgary'], ['Toronto'], ['Calgary'], ['Toronto'], ['Toronto'], ['Toronto'], ['Toronto'], 'Null', ['Toronto'], ['Calgary'], ['Calgary'], ['Toronto'], ['Toronto'], ['Edmonton'], ['Toronto'], ['Edmonton']] \n",
      "\n",
      "DISTANCE: [83.42, 397.56, 0.0, 17.69, 0.0, 27.12, 16.73, 11.65, 45.19, 0.0, 70.89, 0.0, 332.89, 30.54, 125.01, 168.21, 'Null', 258.56, 173.7, 0.0, 153.65, 57.2, 0.0, 232.01, 0.0] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for distances in locations_list:\n",
    "    try:\n",
    "        calc_distance(distances)\n",
    "    except:\n",
    "        nearest_city_list.append('Null')\n",
    "        distance_nearest_city_list.append('Null')\n",
    "\n",
    "print('NEAREST CITY:', nearest_city_list, '\\n')\n",
    "print(f'DISTANCE:', distance_nearest_city_list, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58cbac-b95d-4f07-93a7-b0521241c000",
   "metadata": {},
   "source": [
    "**Inserting data into a Dataframe**\n",
    "\n",
    "To store the job data, the job information dictionary is first converted into a DataFrame using Pandas. This DataFrame is then saved to a CSV file named 'jobs_dataframe.csv' with headers and without row indices. Finally, the CSV file is read back into a new DataFrame named 'improved_jobs_dataframe' and printed to verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d08e1d8f-955f-48c6-a54a-8122b633957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(jobs['ID']))\n",
    "print(len(jobs['ROLES']))\n",
    "print(len(jobs['SALARY']))\n",
    "print(len(jobs['EDUCATION']))\n",
    "print(len(jobs['EXPERIENCE']))\n",
    "print(len(jobs['NOC CODE']))\n",
    "print(len(jobs['BUSINESS']))\n",
    "print(len(jobs['LOCATIONS']))\n",
    "print(len(jobs['PUBLISHED DATES']))\n",
    "print(len(jobs['EMPLOYMENT TYPE']))\n",
    "print(len(jobs['JOB DURATION']))\n",
    "print(len(jobs['WEEKLY HOURS']))\n",
    "print(len(jobs['VACANCIES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b5c891d-25a0-40d7-8b6a-1c41d9700834",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m jobs_dataframe\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(jobs)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#print(jobs_dataframe)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m jobs_dataframe\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobs_dataframe.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:1917\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1911\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1912\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for orient parameter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1913\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morient\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1914\u001b[0m     )\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(data, index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1918\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1919\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "jobs_dataframe=pd.DataFrame.from_dict(jobs)\n",
    "#print(jobs_dataframe)\n",
    "\n",
    "jobs_dataframe.to_csv('jobs_dataframe.csv', header=True, index=False)\n",
    "improved_jobs_dataframe=pd.read_csv('jobs_dataframe.csv')\n",
    "print(improved_jobs_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67c7c84-3baf-4910-9ff0-b27bff4e43c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ON_AB_localization = {\n",
    "    'State': [],\n",
    "    'City': [],\n",
    "    'Lat': [],\n",
    "    'Long': [],\n",
    "    }\n",
    "try:\n",
    "    pd.read_csv(\"ON_AB_localization.csv\")\n",
    "    ON_AB_localization['State'] = df['State'].tolist()\n",
    "    ON_AB_localization['City'] = df['City'].tolist()\n",
    "    ON_AB_localization['Lat'] = df['Lat'].tolist()\n",
    "    ON_AB_localization['Long'] = df['Long'].tolist()\n",
    "except:\n",
    "    ON_AB_localization_ONLY = pd.DataFrame.from_dict(ON_AB_localization)\n",
    "    ON_AB_localization_ONLY.to_csv(\"ON_AB_localization.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf4bea3-4786-4df8-9400-36e7466ad5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_city(fixed_location):\n",
    "    \n",
    "    ON_AB_localization_EXCEL = pd.read_csv(\"ON_AB_localization.csv\")\n",
    "    location= re.sub(r'\\s*\\(ON\\)|\\s*\\(AB\\)', '', fixed_location)\n",
    "    \n",
    "    found = ON_AB_localization_EXCEL[ON_AB_localization_EXCEL['City'] == location]\n",
    "    if not found.empty:\n",
    "        lat = found['Lat'].values[0]\n",
    "        long = found['Long'].values[0]\n",
    "        return lat, long\n",
    "    else:\n",
    "        geolocator = Nominatim(user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36 OPR/109.0.0.0')\n",
    "        \n",
    "        if 'ON' in fixed_location:\n",
    "            ON_AB_localization['State'].append('ON')\n",
    "            locationX = location+\", Ontario\"\n",
    "        \n",
    "        elif 'AB' in fixed_location:\n",
    "            ON_AB_localization['State'].append('AB')\n",
    "            locationX = location + \", Alberta\"\n",
    "        \n",
    "        else:\n",
    "            ON_AB_localization['State'].append('??')\n",
    "            locationx=location\n",
    "        \n",
    "    location_city=geolocator.geocode(locationX)\n",
    "    \n",
    "    if location_city:\n",
    "        city_lat = location_city.latitude\n",
    "        city_long = location_city.longitude\n",
    "        \n",
    "        ON_AB_localization['City'].append(location)\n",
    "        ON_AB_localization['Lat'].append(city_lat)\n",
    "        ON_AB_localization['Long'].append(city_long)\n",
    "    \n",
    "        ON_AB_localization_DICT = pd.DataFrame.from_dict(ON_AB_localization)\n",
    "        ON_AB = pd.concat([ON_AB_localization_EXCEL, ON_AB_localization_DICT], ignore_index=True)\n",
    "        ON_AB = ON_AB.drop_duplicates(subset=['City'], ignore_index=True)\n",
    "        ON_AB.to_csv(\"ON_AB_localization.csv\", header=True, index=False)\n",
    "    \n",
    "        return city_lat, city_long\n",
    "        \n",
    "    else:\n",
    "        print(f\"Location couldn't be retrieved: {locationX}\")\n",
    "        return None, None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49168564-fd20-44fa-bd76-de5297ad97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cities in locations_list:\n",
    "    search_city(cities)\n",
    "ON_AB_localization_EXCEL=pd.read_csv(\"ON_AB_localization.csv\")\n",
    "print(ON_AB_localization_EXCEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650ac8a-460f-4c7f-a1f1-33acf57fba84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de374ad-3889-4dac-abfc-524f3b2b0e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
